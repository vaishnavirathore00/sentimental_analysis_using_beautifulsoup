{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z5J7hitm682K"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import requests\n",
        "from requests.models import MissingSchema\n",
        "import spacy\n",
        "import re\n",
        "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"Input.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jUKTTHiQ8U7Z"
      },
      "outputs": [],
      "source": [
        "def beautifulsoup_extract_text_fallback(response_content):\n",
        "    \n",
        "    \n",
        "    paragraphs = \" \"    \n",
        "    # Create the beautifulsoup object:\n",
        "    soup = BeautifulSoup(response_content, 'html.parser')\n",
        "\n",
        "    for each in soup.find_all('p'):\n",
        "        #each = each.replace('\\t','')\n",
        "        each = remove_tags(str(each))\n",
        "        each = each.replace('\\t', '').strip()\n",
        "        #each = re.sub(r'[^a-zA-Z ]','',each)\n",
        "        #print(each)\n",
        "        paragraphs += each\n",
        "\n",
        "    return paragraphs\n",
        "    \n",
        "def extract_text_from_single_web_page(url):\n",
        "    resp = requests.get(url,headers={\"User-Agent\": \"XY\"})\n",
        "    # We will only extract the text from successful requests:\n",
        "    if resp.status_code == 200:\n",
        "          return beautifulsoup_extract_text_fallback(resp.content)\n",
        "\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)\n",
        "\n",
        "def['paragraph'] = df[\"URL\"].apply(extract_text_from_single_web_page)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MV_cjnFUOAlC"
      },
      "outputs": [],
      "source": [
        "def tokenizer(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z ]','',text)\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    filtered_words = list(filter(lambda token: token not in stopWordList, tokens))\n",
        "    return filtered_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cNSpEjRXQf4K"
      },
      "outputs": [],
      "source": [
        "with open('StopWords_Generic.txt','r') as stop_words:\n",
        "    stopWords = stop_words.read().lower()\n",
        "stopWordList = stopWords.split('\\n')\n",
        "stopWordList[-1:] = []\n",
        "\n",
        "with open('PositiveWords.txt','r') as posfile:\n",
        "    positivewords=posfile.read().lower()\n",
        "positiveWordList=positivewords.split('\\n')\n",
        "\n",
        "with open('NegativeWords.txt','r') as negfile:\n",
        "    negativeword=negfile.read().lower()\n",
        "negativeWordList=negativeword.split('\\n')\n",
        "\n",
        "def positive_Score(text):\n",
        "    positive = 0\n",
        "    text = tokenizer(text)\n",
        "    for each in text:\n",
        "        if each in positiveWordList:\n",
        "            positive += 1\n",
        "    return positive\n",
        "\n",
        "def negative_Score(text):\n",
        "    negative = 0\n",
        "    text = tokenizer(text)\n",
        "    for each in text:\n",
        "        if each in negativeWordList:\n",
        "            negative += 1\n",
        "    return negative\n",
        "\n",
        "def average_sentence_length(text):\n",
        "    return len(tokenizer(text))/len(sent_tokenize(text))\n",
        "\n",
        "def percentage_complex_word(text):\n",
        "    tokens = tokenizer(text)\n",
        "    complexWord = 0\n",
        "    complex_word_percentage = 0\n",
        "    \n",
        "    for word in tokens:\n",
        "        vowels=0\n",
        "        if word.endswith(('es','ed')):\n",
        "            pass\n",
        "        else:\n",
        "            for w in word:\n",
        "                if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
        "                    vowels += 1\n",
        "            if(vowels > 2):\n",
        "                complexWord += 1\n",
        "    if len(tokens) != 0:\n",
        "        complex_word_percentage = complexWord/len(tokens)\n",
        "    \n",
        "    return round(complex_word_percentage*100,2)\n",
        "\n",
        "\n",
        "def word_count(text):\n",
        "    text = re.sub(r'[^a-zA-Z ]','',text)\n",
        "    return len(tokenizer(text))\n",
        "\n",
        "def complex_word_count(text):\n",
        "    text = re.sub(r'[^a-zA-Z ]','',text)\n",
        "    tokens = tokenizer(text)\n",
        "    complexWord = 0\n",
        "    \n",
        "    for word in tokens:\n",
        "        vowels=0\n",
        "        if word.endswith(('es','ed')):\n",
        "            pass\n",
        "        else:\n",
        "            for w in word:\n",
        "                if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
        "                    vowels += 1\n",
        "            if(vowels > 2):\n",
        "                complexWord += 1\n",
        "    return complexWord\n",
        "\n",
        "def count_syllables(word):\n",
        "    return len(\n",
        "        re.findall('(?!e$)[aeiouy]+', word, re.I) +\n",
        "        re.findall('^[^aeiouy]*e$', word, re.I)\n",
        "    )\n",
        "\n",
        "def count_syllablesperoword(text):\n",
        "    count_syllab = 0\n",
        "    tokens = tokenizer(text)\n",
        "    for each in tokens:\n",
        "        count_syllab += count_syllables(each)\n",
        "    return count_syllab/len(tokens)\n",
        "\n",
        "def personal_pronoun(text):\n",
        "    pronounRegex = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
        "    pronouns = pronounRegex.findall(text)\n",
        "    return len(pronouns)\n",
        "\n",
        "def avg_word_length(text):\n",
        "    tokens = tokenizer(text)\n",
        "    total_words = 0\n",
        "    for each in tokens:\n",
        "       total_words += len(each)\n",
        "    return total_words/len(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q9KOHXMRYIdl",
        "outputId": "381d812a-865c-4f9c-c515-25f4795d0daf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b6ef1143-aef0-46ab-acfc-0f3221891dbd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL_ID</th>\n",
              "      <th>URL</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>POSITIVE SCORE</th>\n",
              "      <th>Negaive SCORE</th>\n",
              "      <th>POLARITY SCORE</th>\n",
              "      <th>SUBJECTIVITY SCORE</th>\n",
              "      <th>AVG SENTENCE LENGTH</th>\n",
              "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
              "      <th>FOG INDEX</th>\n",
              "      <th>COMPLEX WORD COUNT</th>\n",
              "      <th>WORD COUNT</th>\n",
              "      <th>SYLLABLE PER WORD</th>\n",
              "      <th>PERSONAL PRONOUNS</th>\n",
              "      <th>AVG WORD LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
              "      <td>When people hear AI they often think about se...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>23.277778</td>\n",
              "      <td>33.65</td>\n",
              "      <td>22.771111</td>\n",
              "      <td>141</td>\n",
              "      <td>419</td>\n",
              "      <td>2.081146</td>\n",
              "      <td>4</td>\n",
              "      <td>6.491647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
              "      <td>With increasing computing power and more data...</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.088235</td>\n",
              "      <td>19.300000</td>\n",
              "      <td>39.12</td>\n",
              "      <td>23.368000</td>\n",
              "      <td>151</td>\n",
              "      <td>386</td>\n",
              "      <td>2.220207</td>\n",
              "      <td>2</td>\n",
              "      <td>6.787565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
              "      <td>If you were a fan of the 90’s film Clueless b...</td>\n",
              "      <td>31</td>\n",
              "      <td>20</td>\n",
              "      <td>0.215686</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>27.230769</td>\n",
              "      <td>43.22</td>\n",
              "      <td>28.180308</td>\n",
              "      <td>459</td>\n",
              "      <td>1062</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>13</td>\n",
              "      <td>7.051789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
              "      <td>Understanding exactly how data is ingested, a...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.666666</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>18.357143</td>\n",
              "      <td>44.75</td>\n",
              "      <td>25.242857</td>\n",
              "      <td>115</td>\n",
              "      <td>257</td>\n",
              "      <td>2.233463</td>\n",
              "      <td>1</td>\n",
              "      <td>6.789883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
              "      <td>From the stone age to the modern world, from ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>-0.047619</td>\n",
              "      <td>0.123529</td>\n",
              "      <td>12.709677</td>\n",
              "      <td>44.67</td>\n",
              "      <td>22.951871</td>\n",
              "      <td>176</td>\n",
              "      <td>394</td>\n",
              "      <td>2.327411</td>\n",
              "      <td>21</td>\n",
              "      <td>6.969543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>167</td>\n",
              "      <td>https://insights.blackcoffer.com/role-big-data...</td>\n",
              "      <td>Can academia, researchers, decision makers an...</td>\n",
              "      <td>17</td>\n",
              "      <td>37</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>0.317647</td>\n",
              "      <td>18.276596</td>\n",
              "      <td>40.51</td>\n",
              "      <td>23.514638</td>\n",
              "      <td>348</td>\n",
              "      <td>859</td>\n",
              "      <td>2.275902</td>\n",
              "      <td>15</td>\n",
              "      <td>6.786962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>168</td>\n",
              "      <td>https://insights.blackcoffer.com/sales-forecas...</td>\n",
              "      <td>Inventory planning is a fundamental part of r...</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>0.290322</td>\n",
              "      <td>0.182353</td>\n",
              "      <td>20.409091</td>\n",
              "      <td>45.21</td>\n",
              "      <td>26.247636</td>\n",
              "      <td>203</td>\n",
              "      <td>449</td>\n",
              "      <td>2.407572</td>\n",
              "      <td>0</td>\n",
              "      <td>7.113586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>169</td>\n",
              "      <td>https://insights.blackcoffer.com/detect-data-e...</td>\n",
              "      <td>Insider threat detection specifically to dete...</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>-0.836735</td>\n",
              "      <td>0.288235</td>\n",
              "      <td>14.261905</td>\n",
              "      <td>42.24</td>\n",
              "      <td>22.600762</td>\n",
              "      <td>253</td>\n",
              "      <td>599</td>\n",
              "      <td>2.419032</td>\n",
              "      <td>6</td>\n",
              "      <td>7.033389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>170</td>\n",
              "      <td>https://insights.blackcoffer.com/data-exfiltra...</td>\n",
              "      <td>If we talk in terms of our general life, Exfi...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047059</td>\n",
              "      <td>13.550000</td>\n",
              "      <td>38.38</td>\n",
              "      <td>20.772000</td>\n",
              "      <td>104</td>\n",
              "      <td>271</td>\n",
              "      <td>2.143911</td>\n",
              "      <td>11</td>\n",
              "      <td>6.464945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>171</td>\n",
              "      <td>https://insights.blackcoffer.com/impacts-of-co...</td>\n",
              "      <td>Some vendors (fruit and vegetable sellers) be...</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.111111</td>\n",
              "      <td>0.052941</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>36.88</td>\n",
              "      <td>21.152000</td>\n",
              "      <td>59</td>\n",
              "      <td>160</td>\n",
              "      <td>2.118750</td>\n",
              "      <td>0</td>\n",
              "      <td>6.556250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6ef1143-aef0-46ab-acfc-0f3221891dbd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6ef1143-aef0-46ab-acfc-0f3221891dbd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6ef1143-aef0-46ab-acfc-0f3221891dbd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     URL_ID                                                URL  \\\n",
              "0         1  https://insights.blackcoffer.com/how-is-login-...   \n",
              "1         2  https://insights.blackcoffer.com/how-does-ai-h...   \n",
              "2         3  https://insights.blackcoffer.com/ai-and-its-im...   \n",
              "3         4  https://insights.blackcoffer.com/how-do-deep-l...   \n",
              "4         5  https://insights.blackcoffer.com/how-artificia...   \n",
              "..      ...                                                ...   \n",
              "165     167  https://insights.blackcoffer.com/role-big-data...   \n",
              "166     168  https://insights.blackcoffer.com/sales-forecas...   \n",
              "167     169  https://insights.blackcoffer.com/detect-data-e...   \n",
              "168     170  https://insights.blackcoffer.com/data-exfiltra...   \n",
              "169     171  https://insights.blackcoffer.com/impacts-of-co...   \n",
              "\n",
              "                                             paragraph  POSITIVE SCORE  \\\n",
              "0     When people hear AI they often think about se...               4   \n",
              "1     With increasing computing power and more data...               9   \n",
              "2     If you were a fan of the 90’s film Clueless b...              31   \n",
              "3     Understanding exactly how data is ingested, a...               5   \n",
              "4     From the stone age to the modern world, from ...              10   \n",
              "..                                                 ...             ...   \n",
              "165   Can academia, researchers, decision makers an...              17   \n",
              "166   Inventory planning is a fundamental part of r...              20   \n",
              "167   Insider threat detection specifically to dete...               4   \n",
              "168   If we talk in terms of our general life, Exfi...               4   \n",
              "169   Some vendors (fruit and vegetable sellers) be...               4   \n",
              "\n",
              "     Negaive SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
              "0                4        0.000000            0.047059            23.277778   \n",
              "1                6        0.200000            0.088235            19.300000   \n",
              "2               20        0.215686            0.300000            27.230769   \n",
              "3                1        0.666666            0.035294            18.357143   \n",
              "4               11       -0.047619            0.123529            12.709677   \n",
              "..             ...             ...                 ...                  ...   \n",
              "165             37       -0.370370            0.317647            18.276596   \n",
              "166             11        0.290322            0.182353            20.409091   \n",
              "167             45       -0.836735            0.288235            14.261905   \n",
              "168              4        0.000000            0.047059            13.550000   \n",
              "169              5       -0.111111            0.052941            16.000000   \n",
              "\n",
              "     PERCENTAGE OF COMPLEX WORDS  FOG INDEX  COMPLEX WORD COUNT  WORD COUNT  \\\n",
              "0                          33.65  22.771111                 141         419   \n",
              "1                          39.12  23.368000                 151         386   \n",
              "2                          43.22  28.180308                 459        1062   \n",
              "3                          44.75  25.242857                 115         257   \n",
              "4                          44.67  22.951871                 176         394   \n",
              "..                           ...        ...                 ...         ...   \n",
              "165                        40.51  23.514638                 348         859   \n",
              "166                        45.21  26.247636                 203         449   \n",
              "167                        42.24  22.600762                 253         599   \n",
              "168                        38.38  20.772000                 104         271   \n",
              "169                        36.88  21.152000                  59         160   \n",
              "\n",
              "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
              "0             2.081146                  4         6.491647  \n",
              "1             2.220207                  2         6.787565  \n",
              "2             2.333333                 13         7.051789  \n",
              "3             2.233463                  1         6.789883  \n",
              "4             2.327411                 21         6.969543  \n",
              "..                 ...                ...              ...  \n",
              "165           2.275902                 15         6.786962  \n",
              "166           2.407572                  0         7.113586  \n",
              "167           2.419032                  6         7.033389  \n",
              "168           2.143911                 11         6.464945  \n",
              "169           2.118750                  0         6.556250  \n",
              "\n",
              "[170 rows x 15 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['POSITIVE SCORE'] = df['paragraph'].apply(positive_Score)\n",
        "df['Negaive SCORE'] = df['paragraph'].apply(negative_Score)\n",
        "df['POLARITY SCORE'] = (df['POSITIVE SCORE'] - df['Negaive SCORE']) / (df['POSITIVE SCORE'] + df['Negaive SCORE']+ 0.00001)\n",
        "df['SUBJECTIVITY SCORE'] = (df['POSITIVE SCORE'] + df['Negaive SCORE']) / (len(df['paragraph'])+ 0.0001)\n",
        "df['AVG SENTENCE LENGTH'] = df['paragraph'].apply(average_sentence_length)\n",
        "df['PERCENTAGE OF COMPLEX WORDS'] = df['paragraph'].apply(percentage_complex_word)\n",
        "df['FOG INDEX'] = 0.4 * (df['AVG SENTENCE LENGTH']  + df['PERCENTAGE OF COMPLEX WORDS'])\n",
        "df['COMPLEX WORD COUNT'] = df['paragraph'].apply(complex_word_count)\n",
        "df['WORD COUNT'] = df['paragraph'].apply(word_count)\n",
        "df['SYLLABLE PER WORD'] = df['paragraph'].apply(count_syllablesperoword)\n",
        "df['PERSONAL PRONOUNS'] = df['paragraph'].apply(personal_pronoun)\n",
        "df['AVG WORD LENGTH'] =  df['paragraph'].apply(avg_word_length)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lC8eEkgYe2w1"
      },
      "outputs": [],
      "source": [
        "df.drop('URL_ID', axis=1, inplace=True)\n",
        "df.drop('paragraph', axis=1, inplace=True)\n",
        "\n",
        "df.to_csv('output_vaishnavi.csv', sep=',', encoding='utf-8', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU21xMAAhMHW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
